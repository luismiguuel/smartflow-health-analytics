{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1e08d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento concluído com sucesso e arquivos salvos!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "def carregar_dados(caminho_arquivo):\n",
    "    \"\"\"Carrega o dataset bruto do arquivo CSV.\"\"\"\n",
    "    return pd.read_csv(caminho_arquivo)\n",
    "\n",
    "def realizar_feature_engineering(df):\n",
    "    \"\"\"\n",
    "    Aplica as transformações de colunas e criação de novas variáveis.\n",
    "    Inclui: One-Hot Encoding do arrival_mode e criação do alerta de oxigênio.\n",
    "    \"\"\"\n",
    "    # One-Hot Encoding: Cria colunas como arrival_ambulance, arrival_walk_in, etc.\n",
    "    df_processado = pd.get_dummies(df, columns=['arrival_mode'], prefix='arrival')\n",
    "    \n",
    "    # Criar Feature Auxiliar baseada em regra clínica\n",
    "    df_processado['low_oxygen_alert'] = (df_processado['oxygen_saturation'] < 92).astype(int)\n",
    "    \n",
    "    return df_processado\n",
    "\n",
    "def dividir_dados(df, target_col='triage_level'):\n",
    "    \"\"\"Separa os dados em atributos (X) e alvo (y) com divisão estratificada.\"\"\"\n",
    "    X = df.drop(target_col, axis=1)\n",
    "    y = df[target_col]\n",
    "    \n",
    "    return train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "def escalonar_features(X_train, X_test, colunas_numericas):\n",
    "    \"\"\"Aplica a padronização (Z-score) nas colunas numéricas.\"\"\"\n",
    "    scaler = RobustScaler()\n",
    "    \n",
    "    # Garantindo que operamos em cópias para evitar avisos do Pandas\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    \n",
    "    X_train_scaled[colunas_numericas] = scaler.fit_transform(X_train[colunas_numericas])\n",
    "    X_test_scaled[colunas_numericas] = scaler.transform(X_test[colunas_numericas])\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "def salvar_datasets(X_train, X_test, y_train, y_test, diretorio_saida=\"../data/processed/\"):\n",
    "    \"\"\"Exporta os arquivos finais para a pasta de dados processados.\"\"\"\n",
    "    X_train.to_csv(f\"{diretorio_saida}X_train.csv\", index=False)\n",
    "    X_test.to_csv(f\"{diretorio_saida}X_test.csv\", index=False)\n",
    "    y_train.to_csv(f\"{diretorio_saida}y_train.csv\", index=False)\n",
    "    y_test.to_csv(f\"{diretorio_saida}y_test.csv\", index=False)\n",
    "\n",
    "def executar_pipeline_preprocessamento():\n",
    "    \"\"\"Função principal que coordena todas as etapas do pré-processamento.\"\"\"\n",
    "    # Definição de caminhos e colunas\n",
    "    ARQUIVO_ENTRADA = \"../data/raw/synthetic_medical_triage.csv\"\n",
    "    COLUNAS_NUMERICAS = [\n",
    "        'age', 'heart_rate', 'systolic_blood_pressure', \n",
    "        'oxygen_saturation', 'body_temperature', 'pain_level', \n",
    "        'chronic_disease_count', 'previous_er_visits'\n",
    "    ]\n",
    "\n",
    "    # Passo 1: Carga\n",
    "    df = carregar_dados(ARQUIVO_ENTRADA)\n",
    "\n",
    "    # Passo 2: Engenharia de Features\n",
    "    df = realizar_feature_engineering(df)\n",
    "\n",
    "    # Passo 3: Divisão (Holdout)\n",
    "    X_train, X_test, y_train, y_test = dividir_dados(df)\n",
    "\n",
    "    # Passo 4: Escalonamento\n",
    "    X_train, X_test = escalonar_features(X_train, X_test, COLUNAS_NUMERICAS)\n",
    "\n",
    "    # Passo 5: Persistência\n",
    "    salvar_datasets(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    print(\"Processamento concluído com sucesso e arquivos salvos!\")\n",
    "\n",
    "\n",
    "executar_pipeline_preprocessamento()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cd53f0",
   "metadata": {},
   "source": [
    "1. Engenharia de Atributos (Feature Engineering)\n",
    "\n",
    "A etapa de engenharia de atributos foi desenhada para transformar os dados brutos em representações que facilitem o aprendizado do modelo, incorporando regras de negócio do domínio médico e tratando limitações estatísticas das variáveis originais. As principais intervenções realizadas foram:\n",
    "\n",
    "1.1. Codificação de Variáveis Categóricas (One-Hot Encoding)\n",
    "A variável arrival_mode (Modo de Chegada), que contém categorias nominais como \"Ambulância\", \"Cadeira de Rodas\" e \"Andando\", foi submetida ao processo de One-Hot Encoding. A escolha por esta técnica, em detrimento de uma codificação ordinal, baseia-se no fato de que não há uma distância matemática fixa e linear entre os modos de transporte. Ao criar colunas binárias independentes para cada modalidade, permitimos que o modelo identifique a forte correlação entre a chegada por ambulância e os níveis de alta urgência (Níveis 2 e 3) sem impor uma hierarquia numérica artificial que poderia enviesar algoritmos lineares ou baseados em distância.\n",
    "\n",
    "1.2. Criação do Indicador de Hipóxia (Low Oxygen Alert)\n",
    "Foi desenvolvida uma variável binária auxiliar denominada low_oxygen_alert, acionada quando a saturação de oxigênio (oxygen_saturation) é inferior a 92%. Esta feature atua como um \"gatilho clínico\" baseado em protocolos reais de triagem hospitalar. Embora a saturação seja uma variável contínua, a relevância clínica de uma variação entre 98% e 95% é mínima comparada à queda de 93% para 90% (estado de hipóxia). A criação deste alerta sinaliza explicitamente ao modelo a transição para um estado crítico, compensando a forte assimetria à esquerda da variável original e facilitando a classificação correta da classe minoritária de pacientes críticos (Nível 3).\n",
    "\n",
    "1.3 Tratamento de Variáveis de Dor e Histórico Clínico\n",
    "As variáveis pain_level, chronic_disease_count e previous_er_visits foram mantidas em seu formato original, passando apenas pelo processo de escalonamento. A análise de frequência demonstrou que essas variáveis, embora assimétricas, possuem uma amplitude limitada (máximo de 10 a 11), o que permite que modelos baseados em árvores de decisão identifiquem os padrões de recorrência e intensidade de dor sem a necessidade de agrupamentos ou transformações agressivas. Essa abordagem preserva a granularidade dos dados de histórico do paciente, fundamentais para a predição de risco em casos de doenças crônicas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d87620",
   "metadata": {},
   "source": [
    "2.0 ESCALONAMENTO\n",
    "\n",
    "Escalonamento Robusto de Atributos Numéricos\n",
    "Considerando que as variáveis numéricas do dataset apresentam escalas e unidades de medida muito distintas — como a Pressão Sistólica, que atinge valores superiores a 160 mmHg, e a Temperatura Corporal, que oscila em uma faixa estreita em torno de 37 °C — aplicou-se o processo de escalonamento utilizando a técnica RobustScaler. Diferente da padronização convencional (Z-score), que utiliza a média e o desvio padrão e é altamente sensível a valores extremos, o escalonamento robusto baseia-se na mediana e no intervalo interquartil. Esta decisão é estratégica para o contexto de triagem médica, pois garante que valores extremos de sinais vitais, como picos de frequência cardíaca ou crises hipertensivas, não sejam tratados como ruídos estatísticos descartáveis, mas sim preservados como indicadores cruciais de gravidade. Ao normalizar os dados dessa forma, asseguramos que o algoritmo atribua importância a cada sinal vital com base em sua relevância clínica, sem que as diferentes magnitudes numéricas ou a presença de outliers legítimos distorçam o aprendizado do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c68ab7b",
   "metadata": {},
   "source": [
    "3.0 Divisão de Dados e Amostragem Estratificada\n",
    "\n",
    "Para a avaliação do desempenho do modelo, os dados foram particionados em conjuntos de treinamento e teste seguindo a proporção de 80% e 20%, respectivamente. A decisão mais crítica nesta etapa foi a implementação da amostragem estratificada, configurada através do parâmetro stratify. Dado que o dataset apresenta um desbalanceamento severo — onde pacientes críticos (Nível 3) representam apenas cerca de 5% do total de amostras — uma divisão puramente aleatória poderia resultar em sub-representação ou ausência total de casos graves em um dos conjuntos. A estratificação garante que a distribuição original das classes seja preservada fielmente tanto no treino quanto no teste. Isso assegura que o modelo tenha exemplos suficientes para aprender os padrões de risco extremo durante o treinamento e, simultaneamente, permite que a sua capacidade de identificar esses casos raros seja validada de forma justa e estatisticamente significativa no conjunto de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09c2609",
   "metadata": {},
   "source": [
    "OBS:\n",
    "\n",
    "Optou-se por não aplicar técnicas de balanceamento artificial no conjunto de dados, como o sobreajuste sintético (oversampling via SMOTE) ou a redução de amostras (undersampling). Esta decisão baseia-se na premissa de que a distribuição original das classes — onde casos de baixa urgência predominam (55%) e casos críticos são raros (5%) — constitui uma característica intrínseca e valiosa do domínio de triagem hospitalar. Alterar essas proporções artificialmente durante o pré-processamento poderia distorcer a realidade operacional que o modelo encontrará em produção, levando-o a uma percepção irreal sobre a frequência de eventos graves e, consequentemente, aumentando a taxa de falsos alarmes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3666d04",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
